# BDP Backend Server Configuration - Production Environment
# This configuration is optimized for production deployment

[server]
host = "0.0.0.0"
port = 8000
workers = 16  # Adjust based on CPU cores
environment = "production"

[server.cors]
enabled = true
# Update with your production domains
origins = [
    "https://bdp.example.com",
    "https://www.bdp.example.com",
    "https://api.bdp.example.com"
]
allow_credentials = true
max_age = 86400  # 24 hours

[database]
# Use environment variable for production
url = "${DATABASE_URL}"
max_connections = 50
min_connections = 10
connect_timeout = 10
acquire_timeout = 30
idle_timeout = 300
max_lifetime = 3600
# Disable query logging in production for performance
log_queries = false
log_slow_queries = true
slow_query_threshold_ms = 500

[database.pool]
test_on_checkout = true
auto_vacuum = true

[storage]
# Production S3 configuration
backend = "s3"
# For AWS S3
endpoint = "https://s3.amazonaws.com"
# Or use environment variable: endpoint = "${S3_ENDPOINT}"
region = "us-east-1"
bucket = "${S3_BUCKET}"
access_key = "${S3_ACCESS_KEY}"
secret_key = "${S3_SECRET_KEY}"
path_style = false  # Use virtual-hosted style for AWS S3
# Presigned URL for downloads
presigned_url_expiry = 3600  # 1 hour

[storage.upload]
max_file_size = 53687091200  # 50 GB
chunk_size = 10485760  # 10 MB
allowed_formats = [
    "fasta", "dat", "xml", "json", "txt", "gz", "zip", "tar", "bz2"
]

[storage.cdn]
# CDN configuration for faster downloads
enabled = true
url = "https://cdn.bdp.example.com"
cache_control = "public, max-age=31536000, immutable"

[api]
base_url = "https://api.bdp.example.com"
max_page_size = 1000
default_page_size = 50
timeout = 60
enable_compression = true

[api.rate_limit]
enabled = true
requests_per_minute = 60
burst_size = 10
strict_mode = true
# IP-based rate limiting
track_by_ip = true
# Rate limit by API key
track_by_api_key = true

[security]
# JWT Configuration - Use environment variable
jwt_secret = "${JWT_SECRET}"
jwt_expiry = 3600  # 1 hour (shorter in production)
jwt_refresh_expiry = 2592000  # 30 days
# Hash rounds for password hashing
password_hash_rounds = 12  # Higher for production

[security.api_keys]
enabled = true
prefix = "bdp_"
length = 48  # Longer keys in production

[security.tls]
# TLS configuration (handled by Caddy, but keep settings)
enabled = true
min_version = "1.3"
hsts_enabled = true
hsts_max_age = 31536000

[logging]
level = "info"
format = "json"  # Structured logging for production
log_sql = false
log_requests = true
log_responses = false
# File logging with rotation
file_enabled = true
file_path = "/var/log/bdp/server.log"
file_rotation = "daily"
file_retention_days = 30
# Send logs to external service
syslog_enabled = false
syslog_endpoint = "syslog://logs.example.com:514"

[ingestion]
# UniProt ingestion settings
enabled = true
schedule = "0 2 * * *"  # Daily at 2 AM UTC
oldest_version = "2020_01"
max_concurrent_downloads = 8
run_on_startup = false

[ingestion.uniprot]
ftp_host = "ftp.uniprot.org"
ftp_path = "/pub/databases/uniprot/current_release/knowledgebase/complete"
ftp_timeout = 600
retry_attempts = 5
retry_delay = 10

[ingestion.processing]
batch_size = 5000
max_memory_mb = 8192
temp_dir = "/var/tmp/bdp-ingestion"
cleanup_on_error = true
# Compress processed files
compression = "gzip"

[cache]
# Redis caching in production
enabled = true
backend = "redis"
ttl = 3600
max_size_mb = 1024

[cache.redis]
url = "${REDIS_URL}"
pool_size = 50
timeout = 5
max_retries = 3
# Cluster mode for high availability
cluster_mode = false

[search]
enabled = true
min_query_length = 2
max_results = 100
fuzzy_search = true
# Use dedicated search engine in production
backend = "elasticsearch"  # Or meilisearch

[search.elasticsearch]
enabled = true
url = "${ELASTICSEARCH_URL}"
index_prefix = "bdp_prod_"
max_connections = 20
timeout = 10
# Index settings
shards = 3
replicas = 2

[metrics]
# Prometheus metrics
enabled = true
port = 9090
path = "/metrics"
format = "prometheus"

[tracing]
# Distributed tracing for debugging
enabled = true
backend = "jaeger"
endpoint = "${JAEGER_ENDPOINT}"
sample_rate = 0.01  # 1% sampling in production

[health_checks]
enabled = true
path = "/health"
# Include dependency checks
check_database = true
check_storage = true
check_cache = true
timeout = 5

[backup]
# Database backup configuration
enabled = true
schedule = "0 3 * * *"  # Daily at 3 AM UTC
retention_days = 30
s3_bucket = "bdp-backups"
encrypt = true

[performance]
# Performance optimizations
enable_http2 = true
enable_compression = true
compression_level = 6
# Connection keep-alive
keep_alive_timeout = 75
# Request body limits
max_request_size = 104857600  # 100 MB
# Graceful shutdown
shutdown_timeout = 30

[notifications]
# Email notifications for critical events
enabled = true
smtp_host = "${SMTP_HOST}"
smtp_port = 587
smtp_user = "${SMTP_USER}"
smtp_password = "${SMTP_PASSWORD}"
from_email = "noreply@bdp.example.com"
admin_emails = ["admin@example.com"]

[maintenance]
# Maintenance mode
enabled = false
message = "BDP is currently undergoing maintenance. Please check back soon."
allowed_ips = ["127.0.0.1"]
